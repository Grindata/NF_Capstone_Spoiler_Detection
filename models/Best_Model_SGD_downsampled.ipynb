{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Silver Speech and Golden Silence: Spoiler Detection Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Stochastic Gradient Descent Classifier (downsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the baseline models on all data, we repeat the procedure on downsampled training data since the dataset is very imbalanced. \n",
    "\n",
    "We chose downsampling the non-spoiler cases instead pf upsampling spoilers since we experienced heavy crashing difficulties with upsampling via SMOTE and similar techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disable scientific notation for floats\n",
    "pd.options.display.float_format = '{:,}'.format\n",
    "\n",
    "#Enable viewing more (in this case: all) features of a dataset\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load datafiles\n",
    "train = pd.read_json('/Users/juliaschafer/NF_Capstone_Spoiler_Detection/data/train_preprocessed.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_json('/Users/juliaschafer/NF_Capstone_Spoiler_Detection/data/validation_preprocessed.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the data is imbalanced, we also try a model with downsampled non-spoilers, accpeting a potential wide loss of information.\n",
    "def downsample_nonspoilers(df):\n",
    "    df_majority = df[df['spoiler_dum'] == 0] #nonspoilers\n",
    "    df_minority = df[df['spoiler_dum'] == 1] #spoilers\n",
    "    \n",
    "    # Downsample majority labels equal to the number of samples in the minority class\n",
    "    df_majority = df_majority.sample(len(df_minority), random_state = 42)\n",
    "\n",
    "    # Concatenate the majority and minority dataframes\n",
    "    sample = pd.concat([df_majority, df_minority])\n",
    "    \n",
    "    sample.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downsample\n",
    "train = downsample_nonspoilers(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: SGD-Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent (SGD) is a simple and very efficient approach to fitting linear classifiers under convex loss functions such as (linear) Support Vector Machines and Logistic Regression. \n",
    "\n",
    "SGD has been successfully applied to large-scale machine learning problems often encountered in text classification and natural language processing. \n",
    "\n",
    "Therefore, we use this a approach as a basic model for spoiler detection.\n",
    "\n",
    "We calculate two kinds of models: In the first one, the reviews are fed sentence-wise to the classifier, in the second one, we give in the whole review. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First model: Feed the reviews sentence-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to transfer the review sentences to a list and then to a numpy array for training.\n",
    "def get_X_sen(df):\n",
    "    \n",
    "    '''Get review sentences from a dataframe df given in.\n",
    "    The review sentences are written in a list 'lst' which is then transformed\n",
    "    into a numpy array'''\n",
    "    \n",
    "    lst = []\n",
    "    for review in df['tokenized']:\n",
    "        for sentence in review:\n",
    "            lst.append(sentence)\n",
    "    X = np.array(lst) \n",
    "    return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to transfer the review labels for each review sentence to a list and then to a numpy array for training.\n",
    "def get_y_sen(df):\n",
    "    \n",
    "    '''Get review labels for each sentence from a dataframe df given in.\n",
    "    The review sentences are written in a list 'llst' which is then transformed\n",
    "    into a numpy array'''\n",
    "    \n",
    "    llst = []\n",
    "    for labellist in df['sentence_labels']:\n",
    "        for label in labellist:\n",
    "            llst.append(label)\n",
    "    y = np.array(llst)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2257873,) (2257873,)\n"
     ]
    }
   ],
   "source": [
    "#Get X and y (train) with sentence-wise review texts\n",
    "X_train_sen = get_X_sen(train)\n",
    "y_train_sen = get_y_sen(train)\n",
    "\n",
    "print(y_train_sen.shape, X_train_sen.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(664558,) (664558,)\n"
     ]
    }
   ],
   "source": [
    "#Get X and y (validation) with sentence-wise review texts\n",
    "X_val_sen = get_X_sen(val)\n",
    "y_val_sen = get_y_sen(val)\n",
    "\n",
    "print(y_val_sen.shape, X_val_sen.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a pipeline for feature extraction with TF IDF and SGD\n",
    "#TFIDF\n",
    "tfidf = TfidfVectorizer(stop_words = 'english', ngram_range = (1,1), min_df = 100, max_features = 5000)\n",
    "#SGD\n",
    "sgd = SGDClassifier(random_state = 42, penalty = 'l2', shuffle = True, n_jobs = -1, max_iter = 1000, \n",
    "                                       loss = 'hinge', class_weight = {0: 0.5, 1: .5}, alpha = .0001)\n",
    "pipe = Pipeline([('tfidf', tfidf),('sgd', sgd)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to run a model and print the classification report\n",
    "def run_sgd(pipeline, X_train, y_train, X_test, y_test):\n",
    "    #Fit the model\n",
    "    sgd = pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    #Predict labels of test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    return print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91    550592\n",
      "           1       0.00      0.00      0.00    113966\n",
      "\n",
      "    accuracy                           0.83    664558\n",
      "   macro avg       0.41      0.50      0.45    664558\n",
      "weighted avg       0.69      0.83      0.75    664558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_sgd(pipe, X_train_sen, y_train_sen, X_val_sen, y_val_sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic model is completely fails to detect spoilers.\n",
    "We tune the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a pipeline for feature extraction with TF IDF and SGD\n",
    "#TFIDF\n",
    "tfidf = TfidfVectorizer(stop_words = 'english', ngram_range = (1,2), min_df = 1)\n",
    "#SGD\n",
    "sgd = SGDClassifier(random_state = 42, penalty = 'elasticnet', alpha = .001, class_weight = {0: 0.3, 1: 0.7}, \n",
    "                    l1_ratio = 0, max_iter = 1000, loss = 'perceptron', shuffle = True, n_jobs = -1)\n",
    "pipe = Pipeline([('tfidf', tfidf), ('sgd', sgd)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90    550592\n",
      "           1       0.52      0.68      0.59    113966\n",
      "\n",
      "    accuracy                           0.84    664558\n",
      "   macro avg       0.73      0.78      0.75    664558\n",
      "weighted avg       0.86      0.84      0.85    664558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_sgd(pipe, X_train_sen, y_train_sen, X_val_sen, y_val_sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second model: review-wise modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the whole review as predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For review-wise model training: Transfer sentences to np.array:\n",
    "def reviewwise_X(df):\n",
    "    reviews = []\n",
    "    for review in df['tokenized']: \n",
    "        reviews.append(' '.join(review))\n",
    "    X = np.array(reviews)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125572,) (125572,)\n"
     ]
    }
   ],
   "source": [
    "X_train_rev = reviewwise_X(train)\n",
    "y_train_rev = train.spoiler_dum\n",
    "print(X_train_rev.shape, y_train_rev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36124,) (36124,)\n"
     ]
    }
   ],
   "source": [
    "X_val_rev = reviewwise_X(val)\n",
    "y_val_rev = val.spoiler_dum\n",
    "print(X_val_rev.shape, y_val_rev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a pipeline for feature extraction with TF IDF and SGD\n",
    "#TFIDF\n",
    "tfidf = TfidfVectorizer(stop_words = 'english', ngram_range = (1,1), min_df = 1)\n",
    "#SGD\n",
    "sgd = SGDClassifier(random_state = 42, penalty = 'l2', shuffle = True, n_jobs = -1, max_iter = 1000, \n",
    "                                       loss = 'hinge', class_weight = {0: 0.4, 1: .6}, alpha = .0001)\n",
    "\n",
    "pipe = Pipeline([('tfidf', tfidf),('sgd', sgd)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.52      0.64     18062\n",
      "           1       0.65      0.89      0.75     18062\n",
      "\n",
      "    accuracy                           0.70     36124\n",
      "   macro avg       0.74      0.70      0.69     36124\n",
      "weighted avg       0.74      0.70      0.69     36124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_sgd(pipe, X_train_rev, y_train_rev, X_val_rev, y_val_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best baseline model is the one with review-wise training and the following hyperparameters:\n",
    "\n",
    "TfidfVectorizer(stop_words = 'english', ngram_range = (1,1), min_df = 1)\n",
    "\n",
    "SGDClassifier(random_state = 42, penalty = 'l2', shuffle = True, n_jobs = -1, max_iter = 1000, \n",
    "                                       loss = 'hinge', class_weight = {0: 0.4, 1: .6}, alpha = .0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
