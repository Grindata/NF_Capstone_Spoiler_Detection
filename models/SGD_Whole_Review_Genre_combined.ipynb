{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Silver Speech and Golden Silence: Spoiler Detection Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review-wise SGD with Metadata (combined in 1 feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train data\n",
    "train = pd.read_json('/Users/juliaschafer/NF_Capstone_Spoiler_Detection/data/train_reduced.json')\n",
    "train.drop(['user_id', 'title'], inplace = True, axis = 1)\n",
    "train.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load validation data\n",
    "val = pd.read_json('/Users/juliaschafer/NF_Capstone_Spoiler_Detection/data/validation_reduced.json')\n",
    "val.drop(['user_id', 'title'], inplace = True, axis = 1)\n",
    "val.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load reviews as a whole for train and validation\n",
    "X_tr = pd.read_csv('/Users/juliaschafer/NF_Capstone_Spoiler_Detection/data/X_train.csv')\n",
    "X_v = pd.read_csv('/Users/juliaschafer/NF_Capstone_Spoiler_Detection/data/X_val.csv')\n",
    "#Rename columns\n",
    "X_tr.rename(columns = {\"0\": 'review_whole'}, inplace = True)\n",
    "X_v.rename(columns = {\"0\": 'review_whole'}, inplace = True)\n",
    "#Drop unnamed columns\n",
    "X_tr.drop('Unnamed: 0', inplace = True, axis = 1)\n",
    "X_v.drop('Unnamed: 0', inplace = True, axis = 1)\n",
    "#Reset indices\n",
    "X_tr.reset_index(drop = True, inplace = True)\n",
    "X_v.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine dataframes and reviews \n",
    "train_df = pd.concat([train, X_tr], axis = 1)\n",
    "val_df = pd.concat([val, X_v], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data for later use\n",
    "train_df.to_json('/Users/juliaschafer/NF_Capstone_Spoiler_Detection/data/train_only_needed_columns.json')\n",
    "val_df.to_json('/Users/juliaschafer/NF_Capstone_Spoiler_Detection/data/val_only_needed_columns.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the data is imbalanced, we downsample the non-spoilers. This further reduces the sample to about 25,000.\n",
    "def downsample_nonspoilers_reviewwise(df):\n",
    "    df_majority = df[df['spoiler_dum'] == 0] #nonspoilers\n",
    "    df_minority = df[df['spoiler_dum'] == 1] #spoilers\n",
    "    N = 2*len(df_minority)\n",
    "    \n",
    "    # Downsample majority labels equals three times the number of samples in the minority class while keeping the original genre proportion\n",
    "    df_majority_ = df_majority.groupby('genre', group_keys = False).apply(lambda x: x.sample(int(np.rint(N*len(x)/len(df))))).sample(frac = 1)\n",
    "\n",
    "    # Concatenate the majority and minority dataframes\n",
    "    sample = pd.concat([df_majority_, df_minority], axis = 0)\n",
    "    \n",
    "    sample.reset_index(inplace = True, drop = True)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked',)).History will not be written to the database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(180169, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = downsample_nonspoilers_reviewwise(train_df)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New column with genre and review text\n",
    "train_df[['text_and_genre']] = train_df.genre + ' ' + train_df.review_whole\n",
    "val_df[['text_and_genre']] = val_df.genre + ' ' + val_df.review_whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('spoiler_dum', axis = 1)\n",
    "y_train = train_df.spoiler_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_df.drop('spoiler_dum', axis = 1)\n",
    "y_val = val_df.spoiler_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rev = X_train.text_and_genre\n",
    "X_val_rev = X_val.text_and_genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline for Balanced Random Forest with Review Texts and Genre Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for model training and prediction\n",
    "def run_model(pipeline, X_train, y_train, X_test, y_test):\n",
    "    #Fit the model\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    #Predict labels of test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    #Print classification report and confusion matrix\n",
    "    return print(classification_report(y_test, y_pred)), print(confusion_matrix(y_test, y_pred, normalize = 'true'))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a pipeline for feature extraction with TF IDF and SGD\n",
    "#TFIDF\n",
    "tfidf = TfidfVectorizer(stop_words = 'english', ngram_range = (1,2), min_df = 100)\n",
    "\n",
    "#Feature Selection: K-Best\n",
    "feat = SelectKBest(score_func = chi2, k = 10000)\n",
    "\n",
    "#SGD\n",
    "sgd = SGDClassifier(random_state = 42, penalty = 'l2', shuffle = True, n_jobs = -1, max_iter = 1000, \n",
    "                                       loss = 'hinge', class_weight = {0: 0.4, 1: .6}, alpha = .0001)\n",
    "\n",
    "pipe = Pipeline([('tfidf', tfidf),('select_kbest', feat), ('SGD', sgd)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.77      0.86    235341\n",
      "           1       0.18      0.68      0.29     18062\n",
      "\n",
      "    accuracy                           0.76    253403\n",
      "   macro avg       0.58      0.72      0.57    253403\n",
      "weighted avg       0.91      0.76      0.82    253403\n",
      "\n",
      "[[0.76803872 0.23196128]\n",
      " [0.3218359  0.6781641 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run the model review-wise (validation)\n",
    "run_model(pipe, X_train_rev.astype('str'), y_train, X_val_rev.astype('str'), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
